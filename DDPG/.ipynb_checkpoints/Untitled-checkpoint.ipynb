{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2017 NVIDIA Corporation\r\n",
      "Built on Fri_Nov__3_21:07:56_CDT_2017\r\n",
      "Cuda compilation tools, release 9.1, V9.1.85\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 20 12:03:50 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.39       Driver Version: 460.39       CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 107...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "|  0%   45C    P8    11W / 180W |    316MiB /  8116MiB |      3%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      2031      G   /usr/lib/xorg/Xorg                 18MiB |\r\n",
      "|    0   N/A  N/A      2288      G   /usr/bin/gnome-shell               61MiB |\r\n",
      "|    0   N/A  N/A      3189      G   /usr/lib/xorg/Xorg                104MiB |\r\n",
      "|    0   N/A  N/A      3331      G   /usr/bin/gnome-shell               85MiB |\r\n",
      "|    0   N/A  N/A      3737      G   ...AAAAAAAAA= --shared-files       41MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the above came up false, follow this\n",
    "#https://www.cyberciti.biz/faq/ubuntu-linux-install-nvidia-driver-latest-proprietary-driver/\n",
    "# from this github issue https://github.com/pytorch/pytorch/issues/15612"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fully connected Q-Network\n",
    "\n",
    "class FCQV(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 output_dim,\n",
    "                 hidden_dims=(32, 32),\n",
    "                 activation_fc=F.relu):\n",
    "        super(FCQV, self).__init__()\n",
    "        self.activation_fc = activation_fc\n",
    "        \n",
    "        \n",
    "        #input layer \n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dims[0])\n",
    "        \n",
    "        #hidden layers\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_dims) -1):\n",
    "            in_dim = hidden_dims[i]\n",
    "            if i == 0:\n",
    "                in_dim += output_dim\n",
    "            hidden_layer = nn.Linear(in_dim, hidden_dims[i+1])\n",
    "            self.hidden_layers.append(hidden_layers)\n",
    "            \n",
    "        #output is a single node representing the value of the state-action pair\n",
    "        self.output_layers = nn.Linear(hidden_dims[-1], 1)\n",
    "        \n",
    "        #use a gpu if you have it \n",
    "        device = \"cpu\"\n",
    "        if torch.cuda.is_available():\n",
    "            device = \"cuda:0\"\n",
    "        #tell the device to work on \n",
    "        self.device = torch.device(device)\n",
    "        self.to(self.device)\n",
    "\n",
    "        \n",
    "        #change the data to torch.Tensors if \n",
    "        def _format(self, state, action):\n",
    "            x, u = state, action\n",
    "            if not isinstance(x, torch.Tensor):\n",
    "                x = torch.tensor(x, \n",
    "                                 device=self.device, \n",
    "                                 dtype=torch.float32)\n",
    "                x = x.unsqueeze(0)\n",
    "            if not isinstance(u, torch.Tensor):\n",
    "                u = torch.tensor(u, \n",
    "                                 device=self.device, \n",
    "                                 dtype=torch.float32)\n",
    "                u = u.unsqueeze(0)\n",
    "            return x, u\n",
    "        \n",
    "        def forward(self, state, available):\n",
    "            x, u = self._format(state, action)\n",
    "            x = self.activation_fc(self.input_layer(x))\n",
    "            for i , hidden_layer in enumerate(self.hidden_layers):\n",
    "                #concatenate the actions to the state on the first hidden layer\n",
    "                if i == 0:\n",
    "                    #add each row value in u to the corresponding row in x\n",
    "                    x = torch.cat((x, u), dim = 1)\n",
    "                x = self.activation_fc(hidden_layer(x))\n",
    "            return self.output_layer(x)\n",
    "        \n",
    "        \n",
    "        # return each state, action, new_states, rewards, and is terminal\n",
    "        def load(self, experiences):\n",
    "            states, actions, new_states, rewards, is_terminal = experiences\n",
    "            states = torch.from_numpy(states).float().to(self.device)\n",
    "            actions = torch.from_numpy(actions).float().to(self.device)\n",
    "            new_states = torch.from_numpy(new_states).float().to(self.device)\n",
    "            rewards = torch.from_numpy(rewards).float().to(self.device)\n",
    "            is_terminals = torch.from_numpy(is_terminals).float().to(self.device)\n",
    "            return states, actions, new_states, rewards, is_terminals\n",
    "        \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fully connected deterministic policy\n",
    "class FCDP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 action_bounds,\n",
    "                 hidden_dims=(32,32),\n",
    "                 activation_fc=F.relu,\n",
    "                 out_activation_fc=F.tanh):   #bound the activation between -1 and 1\n",
    "        super(FCDP, self).__init__()\n",
    "        self.activation_fc = activation_fc\n",
    "        self.out_activation_fc = out_activation_fc\n",
    "        \n",
    "        # set the min and max so that we can rescale the bounds for the return \n",
    "        self.env_min, self.env_max = action_bounds\n",
    "        \n",
    "        #states in, actions out\n",
    "        self.input_layers = nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            hidden_layer = nn.Linear(hidden_dims[i], hidden_dims[i+1])\n",
    "            self.hidden_layers.append(hidden_layer)\n",
    "            self.output_layer = nn.Linear(hidden_dims[-1], len(self.env_max))\n",
    "        \n",
    "        #use a gpu if you have it \n",
    "        device = \"cpu\"\n",
    "        if torch.cuda.is_available():\n",
    "            device = \"cuda:0\"\n",
    "        self.device = torch.device(device)\n",
    "        self.to(self.device)\n",
    "        \n",
    "        # environmental min and max into tensors\n",
    "        self.env_min = torch.tensor(self.env_min,\n",
    "                                    device=self.device, \n",
    "                                    dtype=torch.float32)\n",
    "\n",
    "        self.env_max = torch.tensor(self.env_max,\n",
    "                                    device=self.device, \n",
    "                                    dtype=torch.float32)\n",
    "        \n",
    "        #min and max for a continous distribution\n",
    "        self.nn_min = self.out_activation_fc(\n",
    "            torch.Tensor([float('-inf')])).to(self.device)\n",
    "        self.nn_max = self.out_activation_fc(\n",
    "            torch.Tensor([float('inf')])).to(self.device)\n",
    "        \n",
    "        \n",
    "        self.rescale_fn = lambda x: (x - self.nn_min) * (self.env_max - self.env_min) / \\\n",
    "                                    (self.nn_max - self.nn_min) + self.env_min\n",
    "    \n",
    "        #format the state into a tensor if it is not\n",
    "        def _format(self, state):\n",
    "            x = state\n",
    "            if not isinstance(x, torch.Tensor):\n",
    "                x = torch.tensor(x, \n",
    "                                 device=self.device, \n",
    "                                 dtype=torch.float32)\n",
    "                x = x.unsqueeze(0)\n",
    "            return x\n",
    "\n",
    "    \n",
    "    def forward(self, state):\n",
    "        x = self._format(state) #make sure state is a tensor\n",
    "        x = self.activation_fc(self.input_layer(x)) #input\n",
    "        for hidden_layer in self.hidden_layers:   #hidden layers\n",
    "            x = self.activation_fc(hidden_layer(x)) \n",
    "        x = self.output_layer(x) #output\n",
    "        x = self.out_activation_fc(x) #output activation\n",
    "        return self.rescale_fn(x) #return the rescale of -1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self,\n",
    "                 max_size=10000,\n",
    "                 batch_size=64\n",
    "                ):\n",
    "        #initialize the size of the array\n",
    "        self.ss_mem = np.empty(shape=(max_size), dtype=ndarray)\n",
    "        self.as_mem = np.empty(shape=(max_size), dtype=np.ndarray)\n",
    "        self.rs_mem = np.empty(shape=(max_size), dtype=np.ndarray)\n",
    "        self.ps_mem = np.empty(shape=(max_size), dtype=np.ndarray)\n",
    "        self.ds_mem = np.empty(shape=(max_size), dtype=np.ndarray)\n",
    "        \n",
    "        self.max_size = max_size\n",
    "        self.batch_size = batch_size\n",
    "        self._idx = 0\n",
    "        self.size = 0\n",
    "        \n",
    "    #store the state, action, reward, \n",
    "    def store(self, sample):\n",
    "        s, a, r, p, d = sample\n",
    "        self.ss_mem[self._idx] = s\n",
    "        self.as_mem[self._idx] = a\n",
    "        self.rs_mem[self._idx] = r\n",
    "        self.ps_mem[self._idx] = p\n",
    "        self.ds_mem[self._idx] = d\n",
    "        \n",
    "        self._idx += 1\n",
    "        self._idx = self._idx % self.max_size\n",
    "        \n",
    "        #once size variable adds past the max size it will keep growing\n",
    "        #so the max_size is used after that\n",
    "        self.size += 1\n",
    "        self.size = min(self.size, self.max_size)\n",
    "    \n",
    "    def sample(self, batch_size=None):\n",
    "        if batch_size == None:\n",
    "            batch_size = self.batch_size\n",
    "        idxs = np.random.choice(\n",
    "            self.size, batch_size, replace=False)\n",
    "        experiences = np.vstack(self.ss_mem[idxs]), \\\n",
    "                      np.vstack(self.as_mem[idxs]), \\\n",
    "                      np.vstack(self.rs_mem[idxs]), \\\n",
    "                      np.vstack(self.ps_mem[idxs]), \\\n",
    "                      np.vstack(self.ds_mem[idxs])\n",
    "        return experiences\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyStrategy():\n",
    "    def __init__(self, bounds):\n",
    "        self.low, self.high = bounds\n",
    "        self.ratio_noise_injected = 0\n",
    "        \n",
    "    def selection_action(self, model, state):\n",
    "        with torch.no_grad():\n",
    "            greedy_action = model(state).cpu().detach().data.numpy().squeeze()\n",
    "            \n",
    "        action = np.clip(greedy_action, self.low, self.high)\n",
    "        return np.reshape(action, self.high_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalNoisyDecayStategy():\n",
    "    def __init__(self, bounds, exploration_noise_ratio=0.1):\n",
    "    def select_action(self, model, state, max_exploration=False):\n",
    "        \n",
    "        #to maximize exploration, we set the noise scale to the maximum action\n",
    "        if max_exploration:\n",
    "            noise_scale = self.high\n",
    "        else:\n",
    "            noise_scale = self.noise_ratio * self.high\n",
    "        with torch.no_grad():\n",
    "            greedy_action = model(state).cpu().detach().data\n",
    "            greedy_action = greedy_action.numpy().squeeze()\n",
    "        noise = np.random.normal(loc=0,\n",
    "                                 scale=noise_scale,\n",
    "                                 size=len(self.high))\n",
    "        noisy_action = greedy_action + noise\n",
    "        action = np.clip(noisy_action, self.low, self.high)\n",
    "        self.noise_ratio = self._noise_ratio_update()\n",
    "        return action\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7776, -1.6559,  1.0647,  0.4161,  1.3967,  1.9610],\n",
       "        [-0.5973, -0.1176, -0.0510, -1.0470, -0.7622, -0.2222],\n",
       "        [ 0.8981, -0.0025, -1.0022, -0.1056, -0.0086,  0.9865],\n",
       "        [-0.2384, -0.6869,  0.0637,  0.3867,  0.7549, -1.0014]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 6)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6235, -0.8895, -0.1597, -0.5396,  0.1663, -1.3120],\n",
       "        [-0.6362,  0.9212,  0.0260, -0.4678, -0.5453,  0.4746],\n",
       "        [ 1.1242,  0.6878, -1.0395,  1.2315,  0.4138, -2.2657],\n",
       "        [-0.0937, -1.9000, -0.9943,  1.0722,  0.3126,  0.8512]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn(4, 6)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7776, -1.6559,  1.0647,  0.4161,  1.3967,  1.9610,  1.6235, -0.8895,\n",
       "         -0.1597, -0.5396,  0.1663, -1.3120, -0.7776, -1.6559,  1.0647,  0.4161,\n",
       "          1.3967,  1.9610],\n",
       "        [-0.5973, -0.1176, -0.0510, -1.0470, -0.7622, -0.2222, -0.6362,  0.9212,\n",
       "          0.0260, -0.4678, -0.5453,  0.4746, -0.5973, -0.1176, -0.0510, -1.0470,\n",
       "         -0.7622, -0.2222],\n",
       "        [ 0.8981, -0.0025, -1.0022, -0.1056, -0.0086,  0.9865,  1.1242,  0.6878,\n",
       "         -1.0395,  1.2315,  0.4138, -2.2657,  0.8981, -0.0025, -1.0022, -0.1056,\n",
       "         -0.0086,  0.9865],\n",
       "        [-0.2384, -0.6869,  0.0637,  0.3867,  0.7549, -1.0014, -0.0937, -1.9000,\n",
       "         -0.9943,  1.0722,  0.3126,  0.8512, -0.2384, -0.6869,  0.0637,  0.3867,\n",
       "          0.7549, -1.0014]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x, y, x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "deep-reinforcement-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
